# -*- coding: utf-8 -*-
"""Proyek I_Expert_Kasya Rizkia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1quDWh5_gP5Ho363llxbMyhuS9mB3h2VU

**Proyek Pertama - Predictive Analytics: Airbnb Price**
---
Nama : Kasya Rizkia Putri

Email : kasya.putri14@gmail.com

Dataset : https://www.kaggle.com/datasets/lovishbansal123/airbnb-data?resource=download

**Deskripsi**

Proyek ini bertujuan untuk membuat model machine learning yang dapat memprediksi harga sewa Airbnb berdasarkan fasilitas dan jenis hunian yang disewakan. Model ini akan membantu tuan rumah untuk menentukan harga sewa yang kompetitif dan optimal untuk properti mereka, serta membantu tamu Airbnb untuk menemukan akomodasi yang sesuai dengan anggaran mereka.

# Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

"""# Data Understanding"""

# Load data
airbnb = pd.read_csv('Airbnb_Data.csv')
airbnb

"""**Exploratory Data - Deskripsi Variabel**"""

# Mendapatkan informasi dari dataset
airbnb.info()

# Menghilangkan atau drop fitur yang tidak mempengaruhi harga Airbnb
airbnb = airbnb.drop(['id',
                      'cancellation_policy',
                      'description',
                      'first_review',
                      'amenities',
                      'neighbourhood',
                      'host_has_profile_pic',
                      'host_identity_verified',
                      'host_response_rate',
                      'host_since',
                      'instant_bookable',
                      'last_review',
                      'longitude',
                      'latitude',
                      'name',
                      'number_of_reviews',
                      'review_scores_rating',
                      'thumbnail_url',
                      'zipcode',
                      'cleaning_fee'], axis='columns')

airbnb.describe()

# Mencari missing value
airbnb.isnull().sum()

# Menghapus missing value
airbnb.dropna(inplace=True)
airbnb.isnull().sum().sum()

airbnb.describe()

airbnb.shape

airbnb.info()

"""**Exploratory Data - Univariate Analysis**"""

numerical_ftr = ['log_price', 'accomodates', 'bathrooms', 'bedrooms', 'beds']
categorical_ftr = ['property_type', 'room_type', 'bed_type', 'city']

"""Categorical Feature"""

airbnb.groupby('property_type')['property_type'].agg('count')

# Buat boolean mask
mask = ~airbnb['property_type'].isin(['Bed & Breakfast', 'Boat','Bungalow', 'Dorm', 'Guest suite',
                                      'Villa', 'In-law', 'Camper/RV', 'Boutique hotel', 'Hostel',
                                      'Cabin', 'Timeshare', 'Boat', 'Serviced apartment', 'Castle',
                                      'Treehouse', 'Tipi', 'Vacation home', 'Casa particular', 'Cave',
                                      'Chalet', 'Earth House', 'Guesthouse', 'Hut', 'Island', 'Lighthouse', 'Tent',
                                      'Train', 'Villa', 'Yurt'])
# Drop mask
airbnb = airbnb[mask]

# Fitur Property Type
feature = categorical_ftr[0]
count = airbnb[feature].value_counts()
percent = 100*airbnb[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah':count, 'Persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

airbnb.groupby('room_type')['room_type'].agg('count')

# Fitur Room Type
feature = categorical_ftr[1]
count = airbnb[feature].value_counts()
percent = 100*airbnb[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah':count, 'Persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

airbnb.groupby('bed_type')['bed_type'].agg('count')

# Melakukan drop pada fitur bed_type
airbnb = airbnb.drop(['bed_type'], axis='columns')

airbnb.groupby('city')['city'].agg('count')

# Fitur City
feature = categorical_ftr[3]
count = airbnb[feature].value_counts()
percent = 100*airbnb[feature].value_counts(normalize=True)
df = pd.DataFrame({'Jumlah':count, 'Persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

airbnb.info()

"""Numerical Feature"""

airbnb.hist(bins=50, figsize=(10,10))
plt.show()

"""**Exploratory Analysis - Multivariate Analysis**"""

# Karena harga yang tertera masih berupa log_price, akan diubah menjadi original_price

import math
# Buat kolom baru untuk original_price
airbnb['original_price'] = airbnb['log_price'].apply(math.exp)

# Hapus kolom log_price
del airbnb['log_price']

airbnb.head()

# Categorical Feature
cat_ftr = airbnb.select_dtypes(include='object').columns.to_list()

for col in cat_ftr:
  sns.catplot(x=col, y='original_price', kind='bar', dodge=False, height=4, aspect=3, data=airbnb, palette='Blues')
  plt.title("Average 'original_price' related with - {}".format(col))

# Numerical Feature
plt.figure(figsize=(10,10))
correlation_matrix = airbnb.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Matriks Korelasi untuk Fitur Numerik")

"""# Data Preparation

*One Hot Encoding*
"""

airbnb.info()

# Mengubah fitur kategori menjadi numerik dengan One Hot Encoding
from sklearn.preprocessing import OneHotEncoder
airbnb = pd.get_dummies(data = airbnb, columns=['property_type'])
airbnb = pd.get_dummies(data = airbnb, columns=['room_type'])
airbnb = pd.get_dummies(data = airbnb, columns=['city'])

airbnb.head()

"""*Train Test Split*"""

from sklearn.model_selection import train_test_split

X = airbnb.drop(["original_price"], axis=1)
y = airbnb["original_price"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=123)

print(f'Total sample pada keseluruhan dataset: {len(X)}')
print(f'Total sample pada dataset train: {len(X_train)}')
print(f'Total sample pada dataset test: {len(X_test)}')

"""*Normalization*"""

from sklearn.preprocessing import StandardScaler

numerical_ftr = ['accommodates', 'bathrooms', 'bedrooms', 'beds']
scaler = StandardScaler()
scaler.fit(X_train[numerical_ftr])
X_train[numerical_ftr] = scaler.transform(X_train.loc[:, numerical_ftr])
X_train[numerical_ftr].head()

X_train[numerical_ftr].describe().round(4)

# scaling data test
X_test.loc[:, numerical_ftr] = scaler.transform(X_test[numerical_ftr])

"""# Modeling

**Menentukan model dan parameter terbaik dengan Grid Search**
"""

# Import library yang diperlukan
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error

# mendefinisikan parameter untuk KNN
param_grid_knn = {
    'n_neighbors': np.arange(1, 11),
    'weights': ['uniform', 'distance']
}

# mendefinisikan parameter untuk Random Forest
param_grid_rf = {
    'n_estimators': np.arange(10, 101, 10),
    'max_depth': np.arange(1, 11),
    'min_samples_split': np.arange(2,11)
}

# mendifinisikan parameter Linear Regression
param_grid_lr = {
    'fit_intercept': [True, False],
    'normalize': [True, False]
}

# Menghilangkan 'normalize' parameter pada Linear Regression
param_grid_lr = {
    'fit_intercept': [True, False]
}

# GridSearchCV
knn_model = GridSearchCV(KNeighborsRegressor(), param_grid_knn, cv=5)
knn_model.fit(X_train, y_train)

rf_model = GridSearchCV(RandomForestRegressor(), param_grid_rf, cv=5)
rf_model.fit(X_train, y_train)

lr_model = GridSearchCV(LinearRegression(), param_grid_lr, cv=5)
lr_model.fit(X_train, y_train)

print("Best KNN parameters:", knn_model.best_params_)
print("Best Random Forest parameters:", rf_model.best_params_)
print("Best Linear Regression parameters:", lr_model.best_params_)

"""# Evaluation"""

# Buat variabel MSE
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN', 'RF', 'Linear Regression'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn_model, 'RF': rf_model, 'Linear Regression': lr_model}

# Hitung MSE masing-masing algoritma pada data train dan data test
for name, model in model_dict.items():
  mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
  mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

# Membuat bar chart dari metric di atas
fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

# Membandingkan y_true dengan prediksi ketiga model
prediction = X_test.iloc[7:15].copy()
pred_dict = {'y_true':y_test[7:15]}
for name, model in model_dict.items():
  pred_dict['prediksi_'+name] = model.predict(prediction).round(2)

pd.DataFrame(pred_dict)